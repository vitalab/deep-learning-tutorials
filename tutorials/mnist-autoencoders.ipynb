{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hands-on session 2.1: Variational Autoencoder\n",
    "## Building Autoencoders in PyTorch\n",
    "Inspired by a [similar tutorial](https://blog.keras.io/building-autoencoders-in-keras.html) for Keras by Fran√ßois Chollet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture packages_install\n",
    "\n",
    "# Make sure the notebook's dependencies are installed\n",
    "import sys\n",
    "!{sys.executable} -m pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's start by looking at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from src.visualization.utils import display_data_samples\n",
    "\n",
    "# MNIST consists of 28x28 images, so the size of the data is\n",
    "data_shape = 28, 28\n",
    "data_size = data_shape[0] * data_shape[1]\n",
    "\n",
    "# Download and prepare data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "mnist_train = MNIST(\"../data\", train=True, download=True, transform=transform)\n",
    "mnist_test = MNIST(\"../data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Check data by displaying random images\n",
    "samples_indices = np.random.randint(len(mnist_train), size=10)\n",
    "display_data_samples(data=[mnist_train[sample_idx][0] for sample_idx in samples_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's build a deep deterministic autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Let's define the encoder architecture we want,\n",
    "# with some options to configure the input and output size\n",
    "def make_encoder(data_size, encoding_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(data_size, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, encoding_size),\n",
    "    )\n",
    "\n",
    "# Same thing for the decoder\n",
    "def make_decoder(data_size, encoding_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(encoding_size, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, data_size),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "# Now let's build our networks, with an arbitrary dimensionality of the latent space\n",
    "# and an input and output size depending on the data.\n",
    "encoder = make_encoder(data_size, 32)\n",
    "decoder = make_decoder(data_size, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can train our model, we have to define our training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define some training hyperparameters\n",
    "epochs = 25\n",
    "batch_size = 256\n",
    "\n",
    "def fit(step_fn, encoder, decoder, optimizer, train_data, val_data, device=\"cuda\"):\n",
    "    # Create dataloaders from the data\n",
    "    # Those are PyTorch's abstraction to help iterate over the data\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
    "\n",
    "    # Ensure that the networks are on the requested device\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    fit_pbar = tqdm(range(epochs), desc=\"Training\", unit=\"epoch\")\n",
    "    pbar_metrics = {\"train_loss\": None, \"val_loss\": None}\n",
    "    for epoch in fit_pbar:\n",
    "        # Set model in training mode before training\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        # Train once over all the training data\n",
    "        for x, _ in train_dataloader:\n",
    "            x = x.to(device)    # Move the data tensor to the device\n",
    "            optimizer.zero_grad()   # Make sure gradients are reset\n",
    "            train_loss, _ = step_fn(encoder, decoder, x)    # Forward pass\n",
    "            train_loss.backward()   # Backward pass\n",
    "            optimizer.step()    # Update parameters w.r.t. optimizer and gradients\n",
    "            pbar_metrics[\"train_loss\"] = train_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)\n",
    "\n",
    "        # Set model in eval mode before validation\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        # At the end of the epoch, check performance against the validation data\n",
    "        for x, _ in val_dataloader:\n",
    "            x = x.to(device)    # Move the data tensor to the device\n",
    "            val_loss, _ = step_fn(encoder, decoder, x)\n",
    "            pbar_metrics[\"val_loss\"] = val_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we have to define a training step that's specific to our training algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def autoencoder_step(encoder, decoder, x):\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)   # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    z = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space vector)\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)    # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x) # Compute the reconstruction loss\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*encoder.parameters(), *decoder.parameters()])\n",
    "fit(autoencoder_step, encoder, decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's take a look at the results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.visualization.utils import display_autoencoder_results\n",
    "\n",
    "display_autoencoder_results(mnist_test, lambda x: autoencoder_step(encoder, decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make our autoencoder variational!\n",
    "\n",
    "At a high-level, we have to change the encoder so that it has two outputs (for the mean and variance), instead of one.\n",
    "\n",
    "Do you think we should change the decoder's architecture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "# This time, we should make the latent space 2-dimensional to visualize it easily afterwards\n",
    "encoding_size = 2\n",
    "\n",
    "# In practice, a small trick to easily implement the two heads of the encoder is to simply\n",
    "# double the size of its output. Then, we can slice the output in half during the forward pass!\n",
    "encoder = make_encoder(data_size, encoding_size * 2)\n",
    "decoder = make_decoder(data_size, encoding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to change the training algorithm, since we have to implement the reparametrization trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code"
    }
   },
   "outputs": [],
   "source": [
    "def kl_div(mu, logvar):\n",
    "    kl_div_by_samples = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    return torch.mean(kl_div_by_samples)\n",
    "\n",
    "def vae_step(encoder, decoder, x):\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)   # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    encoding_distr = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space posterior)\n",
    "    # Nothing changed so far!\n",
    "\n",
    "    # Second part of our trick!\n",
    "    # We separate the (unique) latent space posterior into its two halves: mean and logvar\n",
    "    mu, logvar = encoding_distr[:, :encoding_size], encoding_distr[:, encoding_size:]\n",
    "\n",
    "    # Reparametrization trick\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    z = mu + eps * std\n",
    "\n",
    "    # Decoding mostly stays the same. The only difference is the added 4th line below\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)    # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x) # Compute the reconstruction loss\n",
    "    loss += 1e-5 * kl_div(mu, logvar)  # Loss now also includes the KL divergence term\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now it's time to train our variational autoencoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*encoder.parameters(), *decoder.parameters()])\n",
    "fit(vae_step, encoder, decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "display_autoencoder_results(mnist_test, lambda x: vae_step(encoder, decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we've got a latent space in two dimensions, we can easily visualize it and look at how the data was\n",
    "distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.visualization.latent_space import explore_latent_space\n",
    "\n",
    "explore_latent_space(mnist_test, encoder, decoder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
