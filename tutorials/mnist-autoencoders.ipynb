{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hands-on session 2.1: Variational Autoencoder\n",
    "## Building Autoencoders in PyTorch\n",
    "\n",
    "Made by **Nathan Painchaud** and **Pierre-Marc Jodoin** from the Université de Sherbrooke, Canada.\n",
    "\n",
    "Inspired by a [similar tutorial](https://blog.keras.io/building-autoencoders-in-keras.html) for Keras by François Chollet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture packages_install\n",
    "\n",
    "# Make sure the repo's package and its dependencies are installed\n",
    "!pip install -e ../."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture project_path_setup\n",
    "\n",
    "import sys\n",
    "\n",
    "if '../' in sys.path:\n",
    "    print(sys.path)\n",
    "else:\n",
    "    sys.path.append('../')\n",
    "    print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PyTorch programming\n",
    "\n",
    "PyTorch is one of the most widely-used deep-learning library in the world.  Unfortunately, despite all of our efforts to simplify the code as much as possible, some parts of this hands-on session might look a bit cryptic for those who are new to PyTorch.   Ideally, beginners should first get familiar with PyTorch via one or two tutorials such as\n",
    "\n",
    "* [Deep Learning With PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* [Training a Classifier on CIFAR10](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
    "\n",
    "before coding autoencoders.  Unfortunately, you might not have enough time to go through these tutorials during the hands-on limited time.\n",
    "\n",
    "We thus suggest you to start playing around with these two autoencoder notebooks, tweak with some hyperparameters, retrain the networks, and ask questions if you have any.\n",
    "\n",
    "Afterwards, if you want to know more about the nuts and bolts of PyTorch, take the time to navigate through these PyTorch tutorials.  You will see, PyTorch is a formidable tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's start by looking at our data\n",
    "In the next cell, we will load the MNIST dataset and visualize some of its images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from src.visualization.utils import display_data_samples\n",
    "\n",
    "# MNIST consists of 28x28 images, so the size of the data is\n",
    "data_shape = 28, 28\n",
    "data_size = data_shape[0] * data_shape[1]\n",
    "\n",
    "# Download and prepare data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "mnist_train = MNIST(\"../data\", train=True, transform=transform)\n",
    "mnist_test = MNIST(\"../data\", train=False, transform=transform)\n",
    "\n",
    "# Check data by displaying random images\n",
    "samples_indices = np.random.randint(len(mnist_train), size=10)\n",
    "mnist_img_list = [mnist_train[sample_idx][0] for sample_idx in samples_indices]\n",
    "display_data_samples(data=mnist_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# What are `mnist_train` and `mnist_test`?  Let's look at it.\n",
    "print(mnist_train)\n",
    "print(mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### PyTorch datasets\n",
    "\n",
    "Please note that `mnist_train` and `mnist_test` are PyTorch **datasets**.  A dataset is an object that encapsulates data in the form of PyTorch tensors.  You may get access (and visualize) the data with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first training image and its class label\n",
    "sample_image = mnist_train[0][0] # sample_image is a \"PyTorch tensor\"\n",
    "sample_label = mnist_train[0][1] \n",
    "\n",
    "# Convert the Tensor into a numpy array\n",
    "sample_image_np = sample_image.numpy()  \n",
    "print(\"Image size = \", sample_image_np.shape)\n",
    "\n",
    "# Call \"squeeze\" to remove the first dimension\n",
    "sample_image_np = sample_image_np.squeeze(0)\n",
    "print(\"Image size = \", sample_image_np.shape)\n",
    "\n",
    "# Plot\n",
    "plt.imshow(sample_image_np)\n",
    "print(\"The image label is \", sample_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's build a deep deterministic autoencoder\n",
    "\n",
    "Here, we will build a simple autoencoder with only **dense** (aka fully-connected) layers and **ReLUs**.  In pytorch, a dense layer is dubbed **Linear**.\n",
    "\n",
    "Both the encoder and the decocer have **3 layers** and the latent space has **32 dimensions**.\n",
    "\n",
    "Since the pixels have values between 0 and 1, the last activation function is a **Sigmoid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Let's define the encoder architecture we want,\n",
    "# with some options to configure the input and output size\n",
    "def make_encoder(data_size, latent_space_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(data_size, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, latent_space_size),\n",
    "    )\n",
    "\n",
    "# Same thing for the decoder\n",
    "def make_decoder(data_size, latent_space_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(latent_space_size, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, data_size),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "# Now let's build our networks, with an arbitrary dimensionality of the latent space\n",
    "# and an input and output size depending on the data.\n",
    "encoder = make_encoder(data_size, 32)\n",
    "decoder = make_decoder(data_size, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions:\n",
    "    \n",
    "* Can you see how the architecture of the encoder is the dual of that of the decoder?\n",
    "* Why do you think that the decoder has an output **sigmoid** activation function?\n",
    "* What is the latent space size of the autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We also have to define our **forward pass** algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def autoencoder_forward_pass(encoder, decoder, x):\n",
    "    \"\"\"AE forward pass.\n",
    "\n",
    "    Args:\n",
    "        encoder: neural net that predicts a latent vector\n",
    "        decoder: neural net that projects a point in the latent space back into the image space\n",
    "        x: batch of N MNIST images\n",
    "\n",
    "    Returns:\n",
    "        loss: crossentropy loss\n",
    "        x_hat: batch of N reconstructed images\n",
    "    \"\"\"\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)   # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    z = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space vector)\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)    # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x) # Compute the reconstruction loss\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training algorithm\n",
    "\n",
    "Before we can train our model, we have to define our training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define some training hyperparameters\n",
    "epochs = 25\n",
    "batch_size = 256\n",
    "\n",
    "def train(forward_pass_fn, encoder, decoder, optimizer, train_data, val_data, device=\"cuda\"):\n",
    "    # Create dataloaders from the data\n",
    "    # Those are PyTorch's abstraction to help iterate over the data\n",
    "    data_loader_kwargs = {\"batch_size\": batch_size, \"num_workers\": os.cpu_count() - 1, \"pin_memory\": True}\n",
    "    train_dataloader = DataLoader(train_data, shuffle=True, **data_loader_kwargs)\n",
    "    val_dataloader = DataLoader(val_data, **data_loader_kwargs)\n",
    "\n",
    "    # Ensure that the networks are on the requested device (typically a GPU)\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    fit_pbar = tqdm(range(epochs), desc=\"Training\", unit=\"epoch\")\n",
    "    pbar_metrics = {\"train_loss\": None, \"val_loss\": None}\n",
    "    for epoch in fit_pbar:\n",
    "\n",
    "        # Train once over all the training data\n",
    "        for x, _ in train_dataloader:\n",
    "            x = x.to(device)    # Move the data tensor to the device\n",
    "            optimizer.zero_grad()   # Make sure gradients are reset\n",
    "            train_loss, _ = forward_pass_fn(encoder, decoder, x)    # Forward pass\n",
    "            train_loss.backward()   # Backward pass\n",
    "            optimizer.step()    # Update parameters w.r.t. optimizer and gradients\n",
    "            pbar_metrics[\"train_loss\"] = train_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)\n",
    "\n",
    "        # At the end of the epoch, check performance against the validation data\n",
    "        for x, _ in val_dataloader:\n",
    "            x = x.to(device)    # Move the data tensor to the device\n",
    "            val_loss, _ = forward_pass_fn(encoder, decoder, x)\n",
    "            pbar_metrics[\"val_loss\"] = val_loss.item()\n",
    "            fit_pbar.set_postfix(pbar_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions:\n",
    "\n",
    "The previous `train(...)` function contains a typical **PyTorch training loop**.  That training loop contains a **forward pass**, a **backward pass**, a **gradient step** (*optimizer.step()*) and a **validation check**.  Also, common to PyTorch are **data loaders**.  A data loader is an object that encapsulates a dataset and provides an iterable over its content.\n",
    "\n",
    "* Do you see what the data loaders are used for?\n",
    "* Do you see what the forward pass does?  What are the inputs and outputs of that function?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*encoder.parameters(), *decoder.parameters()])\n",
    "train(autoencoder_forward_pass, encoder, decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's take a look at the results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.visualization.utils import display_autoencoder_results\n",
    "\n",
    "display_autoencoder_results(mnist_test, lambda x: autoencoder_forward_pass(encoder, decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Latent space\n",
    "\n",
    "Before we move on to the variational autoencoder, go back to the beginning of this notebook and replace the 32 latent space size by a size of 2 and retrain the autoencoder.\n",
    "\n",
    "Once this is done, execute the following cell to visualize the latent space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell only if the autoencoder has a latent space size of 2.\n",
    "\n",
    "from src.visualization.latent_space import explore_latent_space\n",
    "\n",
    "latent_space_size = 2\n",
    "\n",
    "explore_latent_space(\n",
    "    mnist_test,\n",
    "    lambda x: encoder(torch.flatten(x, start_dim=1)),\n",
    "    lambda z: decoder(z).reshape(data_shape),\n",
    "    encodings_label=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Question :\n",
    "\n",
    "Why do you think that with a 2D latent space we end up reconstructing less accurate (more blurry) images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Let's turn our autoencoder variational\n",
    "\n",
    "Variational autoencoders (VAE) are very similar to autoencoders.  The differences are threefold:\n",
    "\n",
    "* The VAE's encoder ouputs mean and variance vectors\n",
    "* The input of the decoder is a vector, randomly sampled, from a Normal distribution determined by the predicted mean and variance vectors \n",
    "* The loss has 2 terms: the reconstruction loss (like for the normal AE) + the KL divergence (for the encoder's output)\n",
    "\n",
    "Since gradient cannot back-propagate into a random sampling method, VAE always come with a **reparametrization trick**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "# This time, we start right away with a 2D latent space to visualize it easily afterwards\n",
    "latent_space_size = 2\n",
    "\n",
    "# In practice, a small trick to easily implement the two heads of the encoder is to simply\n",
    "# double the size of its output. Then, we can slice the output in half during the forward pass!\n",
    "vae_encoder = make_encoder(data_size, latent_space_size * 2) \n",
    "vae_decoder = make_decoder(data_size, latent_space_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Questions:\n",
    "\n",
    "* In the previous cell, we used the same function to build our VAE's encoder and decoder networks than the AE.  The only difference is the output size of the encoder is multiplied by 2.  Why do you think that is?\n",
    "* In the next cell, we include the **reparametrization trick** to the **forward pass**.  Remember why this has to be done?\n",
    "* What is the latent space size of the VAE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We also need to change the training algorithm, since we have to implement the **reparametrization trick**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "def kl_div(mu, logvar):\n",
    "    kl_div_by_samples = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n",
    "    return torch.mean(kl_div_by_samples)\n",
    "\n",
    "def vae_forward_pass(encoder, decoder, x):\n",
    "    \"\"\"VAE forward pass.\n",
    "\n",
    "    Args:\n",
    "        encoder: neural net that predicts a mean and a logvar vector\n",
    "        decoder: neural net that projects a point in the latent space back into the image space\n",
    "        x: batch of N MNIST images\n",
    "\n",
    "    Returns:\n",
    "        loss: crossentropy + kl_divergence loss\n",
    "        x_hat: batch of N reconstructed images\n",
    "    \"\"\"\n",
    "    in_shape = x.shape  # Save the input shape\n",
    "    encoder_input = torch.flatten(x, start_dim=1)  # Flatten the 2D image to a 1D tensor (for the linear layer)\n",
    "    encoding_distr = encoder(encoder_input)  # Forward pass on the encoder (to get the latent space posterior)\n",
    "    # Nothing changed so far!\n",
    "\n",
    "    # Second part of our trick!\n",
    "    # We separate the (unique) latent space posterior into its two halves: mean and logvar\n",
    "    mu, logvar = encoding_distr[:, :latent_space_size], encoding_distr[:, latent_space_size:]\n",
    "\n",
    "    # Reparametrization trick\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    z = mu + eps * std\n",
    "\n",
    "    # Decoding mostly stays the same. The only difference is the added 4th line below\n",
    "    x_hat = decoder(z)  # Forward pass on the decoder (to get the reconstructed input)\n",
    "    x_hat = x_hat.reshape(in_shape)    # Restore the output to the original shape\n",
    "    loss = F.binary_cross_entropy(x_hat, x) # Compute the reconstruction loss\n",
    "    loss += 5e-3 * kl_div(mu, logvar)  # Loss now also includes the KL divergence term\n",
    "    return loss, x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now it's time to train our variational autoencoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*vae_encoder.parameters(), *vae_decoder.parameters()])\n",
    "train(vae_forward_pass, vae_encoder, vae_decoder, optimizer, mnist_train, mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let's take a look at the results on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "display_autoencoder_results(mnist_test, lambda x: vae_forward_pass(vae_encoder, vae_decoder, x.cuda())[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## More visualization \n",
    "\n",
    "Now that we have a latent space in two dimensions, we can easily visualize it and look at how the data is\n",
    "distributed.\n",
    "\n",
    "### See the difference between this latent space and that of the previous autoencoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% code\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.visualization.latent_space import explore_latent_space\n",
    "\n",
    "explore_latent_space(\n",
    "    mnist_test,\n",
    "    lambda x: vae_encoder(torch.flatten(x, start_dim=1))[:, :latent_space_size],\n",
    "    lambda z: vae_decoder(z).reshape(data_shape),\n",
    "    encodings_label=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### In the next cell, we shall decode one selected vector `z` in the latent space.  Change the content of that vector and you will see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = [-1, -1]  # 2D latent vector\n",
    "\n",
    "z_torch = torch.tensor(z, dtype=torch.float).cuda()  # convert Z into a PyTorch tensor\n",
    "\n",
    "sample = vae_decoder(z_torch).reshape(data_shape)  # decode the latent vector with the VAE decoder\n",
    "\n",
    "plt.imshow(sample.detach().cpu().numpy()) # plot the resulting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
